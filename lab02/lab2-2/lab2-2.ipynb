{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-02-23 11:26:33--  https://github.com/ONNC/onnc-tutorial/raw/master/models/lenet/lenet.onnx\n",
      "Resolving github.com (github.com)... 20.27.177.113\n",
      "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/ONNC/onnc-tutorial/master/models/lenet/lenet.onnx [following]\n",
      "--2024-02-23 11:26:34--  https://raw.githubusercontent.com/ONNC/onnc-tutorial/master/models/lenet/lenet.onnx\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 13102084 (12M) [application/octet-stream]\n",
      "Saving to: ‘models/lenet.onnx’\n",
      "\n",
      "lenet.onnx          100%[===================>]  12.50M  8.67MB/s    in 1.4s    \n",
      "\n",
      "2024-02-23 11:26:38 (8.67 MB/s) - ‘models/lenet.onnx’ saved [13102084/13102084]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -P models https://github.com/ONNC/onnc-tutorial/raw/master/models/lenet/lenet.onnx "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab 2-2-2 Visualizing the Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b259b8f3893f47c795a4eb18c37b882b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b26e7023357430f9a4629865bd3e1ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26af42b1c7d646548f99d9da5461c4fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d4579db1c65457d9f144e65c46b077f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc99cd4deeb442af8fc085d9b2aa9be5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Model must be in evaluation mode for export\n",
    "model.eval()\n",
    "\n",
    "# Create dummy input for the model. It should match the input shape that the model expects.\n",
    "# For BERT, typically this is a sequence of token IDs.\n",
    "dummy_input = tokenizer.encode_plus(\"Hello, my dog is cute\", \n",
    "                                    add_special_tokens=True, \n",
    "                                    max_length=512, \n",
    "                                    return_tensors=\"pt\")\n",
    "\n",
    "# Convert inputs to appropriate format for model\n",
    "input_ids = dummy_input['input_ids']\n",
    "attention_mask = dummy_input['attention_mask']\n",
    "\n",
    "# Export the model to an ONNX file\n",
    "torch.onnx.export(model, \n",
    "                  (input_ids, attention_mask), \n",
    "                  \"models/transformer.onnx\", \n",
    "                  opset_version=11, \n",
    "                  do_constant_folding=True, \n",
    "                  input_names=['input_ids', 'attention_mask'], \n",
    "                  output_names=['output'], \n",
    "                  dynamic_axes={'input_ids': {0: 'batch_size'}, \n",
    "                                'attention_mask': {0: 'batch_size'}, \n",
    "                                'output': {0: 'batch_size'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/Hank/projects/lab02/lab2-2\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
