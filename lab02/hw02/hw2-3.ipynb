{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40f0a94c-6246-4375-8e4d-8a314813a273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import onnx\n",
    "from onnx import shape_inference\n",
    "import sys\n",
    "from tabulate import tabulate\n",
    "from onnx import onnx_ml_pb2 as xpb2\n",
    "import onnx.helper as helper\n",
    "from onnx import numpy_helper\n",
    "import numpy as np\n",
    "from onnx import TensorProto\n",
    "import onnxruntime as ort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769bb1be-d17b-4270-8442-4b96a82541df",
   "metadata": {},
   "source": [
    "### Build a GEMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7daa0f64-eabf-4e16-bf87-52206a265b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "M, N, K = 128, 128, 128\n",
    "graph_def = helper.make_graph(\n",
    "    nodes=[],\n",
    "    name='Gemm',\n",
    "    inputs=[\n",
    "        helper.make_tensor_value_info('A', onnx.TensorProto.FLOAT, [M, N]),\n",
    "        helper.make_tensor_value_info('B', onnx.TensorProto.FLOAT, [N, K]),\n",
    "        helper.make_tensor_value_info('C', onnx.TensorProto.FLOAT, [K])\n",
    "    ],\n",
    "    outputs=[\n",
    "        helper.make_tensor_value_info('OUT', onnx.TensorProto.FLOAT, [M, K])\n",
    "    ],\n",
    ")\n",
    "\n",
    "gemm = helper.make_node(\n",
    "    op_type='Gemm',\n",
    "    inputs=['A', 'B', 'C'],\n",
    "    outputs=['OUT'],\n",
    ")\n",
    "graph_def.node.extend([gemm])\n",
    "\n",
    "# Create the ONNX model\n",
    "model_def = helper.make_model(graph_def, producer_name='simple_gemm')\n",
    "\n",
    "# Save the ONNX model to a file\n",
    "onnx.save(model_def, './models/simple_gemm.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5d72df-5303-447c-abd8-16690bb5c822",
   "metadata": {},
   "source": [
    "### Build 64x64x64 Limit GEMM Layer with Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0db7bfdb-a0ea-4386-bd89-1e66eedc62b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Build_GEMM(M, N, K, Block_Size, model_name, input_A_name, input_B_name, input_C_name, output_name):\n",
    "    M_blocks = (M + Block_Size - 1) // Block_Size\n",
    "    N_blocks = (N + Block_Size - 1) // Block_Size\n",
    "    K_blocks = (K + Block_Size - 1) // Block_Size\n",
    "    \n",
    "    graph_def = helper.make_graph(\n",
    "        nodes=[],\n",
    "        name='my_model',\n",
    "        inputs=[\n",
    "            helper.make_tensor_value_info(input_A_name, onnx.TensorProto.FLOAT, [M, N]),\n",
    "            helper.make_tensor_value_info(input_B_name, onnx.TensorProto.FLOAT, [N, K]),\n",
    "            helper.make_tensor_value_info(input_C_name, onnx.TensorProto.FLOAT, [K])\n",
    "        ],\n",
    "        outputs=[\n",
    "            helper.make_tensor_value_info(output_name, onnx.TensorProto.FLOAT, [M, K])\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Create the Split nodes\n",
    "    split_A_names1 = [f'A{i}' for i in range(M_blocks)]\n",
    "    split_A_row = helper.make_node(\n",
    "        op_type='Split',\n",
    "        inputs=[input_A_name],\n",
    "        outputs=split_A_names1,\n",
    "        axis=0,\n",
    "        num_outputs=M_blocks\n",
    "    )\n",
    "    graph_def.node.extend([split_A_row])\n",
    "    \n",
    "    # Split along axis 2\n",
    "    for i in range(M_blocks):\n",
    "        split_A_names2 = [f'A{i}/{j}' for j in range(N_blocks)]\n",
    "        split_A_col = helper.make_node(\n",
    "            op_type='Split',\n",
    "            inputs=[split_A_names1[i]],\n",
    "            outputs=split_A_names2,\n",
    "            axis=1,\n",
    "            num_outputs=N_blocks\n",
    "        )\n",
    "        graph_def.node.extend([split_A_col])\n",
    "    \n",
    "    # Create the Split nodes\n",
    "    split_B_names1 = [f'B{i}' for i in range(N_blocks)]\n",
    "    split_B_row = helper.make_node(\n",
    "        op_type='Split',\n",
    "        inputs=[input_B_name],\n",
    "        outputs=split_B_names1,\n",
    "        axis=0,\n",
    "        num_outputs=N_blocks\n",
    "    )\n",
    "    graph_def.node.extend([split_B_row])\n",
    "    \n",
    "    # Split along axis 2\n",
    "    for i in range(N_blocks):\n",
    "        split_B_names2 = [f'B{i}/{j}' for j in range(K_blocks)]\n",
    "        split_B_col = helper.make_node(\n",
    "            op_type='Split',\n",
    "            inputs=[split_B_names1[i]],\n",
    "            outputs=split_B_names2,\n",
    "            axis=1,\n",
    "            num_outputs=K_blocks\n",
    "        )\n",
    "        graph_def.node.extend([split_B_col])\n",
    "    \n",
    "    # Loop through matrix multiplication\n",
    "    for i in range(M_blocks):\n",
    "        for j in range(K_blocks):\n",
    "            for k in range(N_blocks):\n",
    "                mul_node = helper.make_node('MatMul', [f'A{i}/{k}', f'B{k}/{j}'], [f'C{i}/{j}/{k}'])\n",
    "                graph_def.node.extend([mul_node])\n",
    "\n",
    "    # Add\n",
    "    for i in range(M_blocks):\n",
    "        for j in range(K_blocks):\n",
    "            if (N_blocks == 1):\n",
    "                copy_node = helper.make_node('Identity', inputs=[f'C{i}/{j}/{0}'], outputs=[f'C{i}/{j}'])\n",
    "                graph_def.node.extend([copy_node])\n",
    "            else:\n",
    "                name_list = [f'C{i}/{j}/{k}' for k in range(N_blocks)]\n",
    "                count = 0\n",
    "                while (len(name_list) > 2):\n",
    "                    add_node = helper.make_node('Add', inputs=[name_list[0], name_list[1]], outputs=[f'temp{i}/{j}/{count}'])\n",
    "                    graph_def.node.extend([add_node])\n",
    "                    name_list.pop(0)\n",
    "                    name_list.pop(0)\n",
    "                    name_list.append(f'temp{i}/{j}/{count}')\n",
    "                    count += 1\n",
    "                add_node = helper.make_node('Add', inputs=[name_list[0], name_list[1]], outputs=[f'C{i}/{j}'])\n",
    "                graph_def.node.extend([add_node])\n",
    "\n",
    "    for i in range(M_blocks):\n",
    "        concat_node = helper.make_node('Concat', inputs=[f'C{i}/{j}' for j in range(K_blocks)], outputs=[f'C{i}'], axis=1)\n",
    "        graph_def.node.extend([concat_node])\n",
    "    \n",
    "    concat_node = helper.make_node('Concat', inputs=[f'C{i}' for i in range(M_blocks)], outputs=['output_wt_bias'], axis=0)\n",
    "    graph_def.node.extend([concat_node])\n",
    "\n",
    "    add_node = helper.make_node('Add', inputs=['output_wt_bias', input_C_name], outputs=[output_name])\n",
    "    graph_def.node.extend([add_node])\n",
    "    # Create the ONNX model\n",
    "    model_def = helper.make_model(graph_def, producer_name=model_name)\n",
    "    \n",
    "    # Save the ONNX model to a file\n",
    "    onnx.save(model_def, './models/' + model_name + '.onnx')\n",
    "    pass\n",
    "\n",
    "M, N, K, BLOCK_SIZE = 128, 128, 128, 64\n",
    "Build_GEMM(M, N, K, BLOCK_SIZE, 'my_model', 'A', 'B', 'C', 'OUT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a72c7fe-33ff-4945-ac4a-5f966a893614",
   "metadata": {},
   "source": [
    "### Load My Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4770ed87-1bd8-414d-be99-8defee9922ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = onnx.load(\"./models/my_model.onnx\", load_external_data=False)\n",
    "onnx.checker.check_model(onnx_model)\n",
    "simple = onnx.load(\"./models/simple_gemm.onnx\", load_external_data=False)\n",
    "onnx.checker.check_model(simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9855911-0bed-4746-80c9-3ed16b12e0bf",
   "metadata": {},
   "source": [
    "### Inference Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7baba70b-7548-42ad-854d-365d6e25d482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Test for My GEMM\n",
      "True\n",
      "(1, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "onnx_session = ort.InferenceSession(\"./models/my_model.onnx\")\n",
    "onnx_session2 = ort.InferenceSession(\"./models/simple_gemm.onnx\")\n",
    "A_name = onnx_session.get_inputs()[0].name\n",
    "B_name = onnx_session.get_inputs()[1].name\n",
    "C_name = onnx_session.get_inputs()[2].name\n",
    "\n",
    "A = np.random.rand(M, N).astype(np.float32)\n",
    "B = np.random.rand(N, K).astype(np.float32)\n",
    "C = np.random.rand(K).astype(np.float32)\n",
    "\n",
    "onnx_output = onnx_session.run(None, {A_name: A, B_name: B, C_name: C})\n",
    "onnx_output2 = onnx_session2.run(None, {A_name: A, B_name: B, C_name: C})\n",
    "\n",
    "print(\"Inference Test for My GEMM\")\n",
    "print(np.allclose(np.array(onnx_output), np.array(onnx_output2), atol = 0))\n",
    "print(np.array(onnx_output).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3855a6d9-2ea7-4189-96d1-af07465a0728",
   "metadata": {},
   "source": [
    "### Load Alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edeff6d9-44a2-4ff4-87e1-c8ca801bb8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape inference complete ...\n"
     ]
    }
   ],
   "source": [
    "alexnet_model = onnx.load(\"./models/alexnet.onnx\", load_external_data=False)\n",
    "onnx.checker.check_model(alexnet_model)\n",
    "\n",
    "inferred_model = shape_inference.infer_shapes(alexnet_model)\n",
    "print('shape inference complete ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ceb6de0-ea4c-4d6b-96de-31a337242842",
   "metadata": {},
   "source": [
    "### Get GEMM Layer names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c01f1846-d775-4f44-85c6-4780e36acd20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/classifier/classifier.1/Gemm', '/classifier/classifier.4/Gemm', '/classifier/classifier.6/Gemm']\n",
      "[['/Flatten_output_0', 'learned_10', 'learned_11'], ['/classifier/classifier.2/Relu_output_0', 'learned_12', 'learned_13'], ['/classifier/classifier.5/Relu_output_0', 'learned_14', 'learned_15']]\n",
      "[['/classifier/classifier.1/Gemm_output_0'], ['/classifier/classifier.4/Gemm_output_0'], ['output1']]\n"
     ]
    }
   ],
   "source": [
    "GEMM_Layer_names = []\n",
    "GEMM_Layer_input_names = []\n",
    "GEMM_Layer_output_names = []\n",
    "for node in alexnet_model.graph.node:\n",
    "    if node.op_type == 'Gemm':\n",
    "        GEMM_Layer_names.append(node.name)\n",
    "        GEMM_Layer_input_names.append(node.input)\n",
    "        GEMM_Layer_output_names.append(node.output)\n",
    "        \n",
    "print(GEMM_Layer_names)\n",
    "print(GEMM_Layer_input_names)\n",
    "print(GEMM_Layer_output_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff2f7c5-7a2b-46e6-b83a-1f942c95108e",
   "metadata": {},
   "source": [
    "### Build My GEMM Layer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52787d77-89f4-400f-9fda-959b11d2707e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Build_GEMM2(M, N, K, Block_Size, index, input_A_name, input_B_name, input_C_name, output_name, graph_def):\n",
    "    M_blocks = (M + Block_Size - 1) // Block_Size\n",
    "    N_blocks = (N + Block_Size - 1) // Block_Size\n",
    "    K_blocks = (K + Block_Size - 1) // Block_Size\n",
    "    \n",
    "    # Create the Split nodes\n",
    "    split_A_names1 = [f'{index} A{i}' for i in range(M_blocks)]\n",
    "    split_A_row = helper.make_node(\n",
    "        op_type='Split',\n",
    "        inputs=[input_A_name],\n",
    "        outputs=split_A_names1,\n",
    "        axis=0,\n",
    "        num_outputs=M_blocks\n",
    "    )\n",
    "    graph_def.node.extend([split_A_row])\n",
    "\n",
    "    # Split along axis 2\n",
    "    for i in range(M_blocks):\n",
    "        split_A_names2 = [f'{index} A{i}/{j}' for j in range(N_blocks)]\n",
    "        split_A_col = helper.make_node(\n",
    "            op_type='Split',\n",
    "            inputs=[split_A_names1[i]],\n",
    "            outputs=split_A_names2,\n",
    "            axis=1,\n",
    "            num_outputs=N_blocks\n",
    "        )\n",
    "        graph_def.node.extend([split_A_col])\n",
    "    \n",
    "    # Create the Split nodes\n",
    "    Trans = helper.make_node(\n",
    "        'Transpose',\n",
    "        inputs=[input_B_name],\n",
    "        outputs=[f'{index} BT'],\n",
    "    )\n",
    "    graph_def.node.extend([Trans])\n",
    "    \n",
    "    split_B_names1 = [f'{index} B{i}' for i in range(N_blocks)]\n",
    "    split_B_row = helper.make_node(\n",
    "        op_type='Split',\n",
    "        inputs=[f'{index} BT'],\n",
    "        outputs=split_B_names1,\n",
    "        axis=0,\n",
    "        num_outputs=N_blocks\n",
    "    )\n",
    "    graph_def.node.extend([split_B_row])\n",
    "    \n",
    "    # Split along axis 2\n",
    "    for i in range(N_blocks):\n",
    "        split_B_names2 = [f'{index} B{i}/{j}' for j in range(K_blocks)]\n",
    "        split_B_col = helper.make_node(\n",
    "            op_type='Split',\n",
    "            inputs=[split_B_names1[i]],\n",
    "            outputs=split_B_names2,\n",
    "            axis=1,\n",
    "            num_outputs=K_blocks\n",
    "        )\n",
    "        graph_def.node.extend([split_B_col])\n",
    "    \n",
    "    # Loop through matrix multiplication\n",
    "    for i in range(M_blocks):\n",
    "        for j in range(K_blocks):\n",
    "            for k in range(N_blocks):\n",
    "                mul_node = helper.make_node('MatMul', [f'{index} A{i}/{k}', f'{index} B{k}/{j}'], [f'{index} C{i}/{j}/{k}'])\n",
    "                graph_def.node.extend([mul_node])\n",
    "    # Add\n",
    "    for i in range(M_blocks):\n",
    "        for j in range(K_blocks):\n",
    "            if (N_blocks == 1):\n",
    "                copy_node = helper.make_node('Identity', inputs=[f'{index} C{i}/{j}/{0}'], outputs=[f'{index} C{i}/{j}'])\n",
    "                graph_def.node.extend([copy_node])\n",
    "            else:\n",
    "                name_list = [f'{index} C{i}/{j}/{k}' for k in range(N_blocks)]\n",
    "                count = 0\n",
    "                while (len(name_list) > 2):\n",
    "                    add_node = helper.make_node('Add', inputs=[name_list[0], name_list[1]], outputs=[f'{index} temp{i}/{j}/{count}'])\n",
    "                    graph_def.node.extend([add_node])\n",
    "                    name_list.pop(0)\n",
    "                    name_list.pop(0)\n",
    "                    name_list.append(f'{index} temp{i}/{j}/{count}')\n",
    "                    count += 1\n",
    "                add_node = helper.make_node('Add', inputs=[name_list[0], name_list[1]], outputs=[f'{index} C{i}/{j}'])\n",
    "                graph_def.node.extend([add_node])\n",
    "                \n",
    "    for i in range(M_blocks):\n",
    "        concat_node = helper.make_node('Concat', inputs=[f'{index} C{i}/{j}' for j in range(K_blocks)], outputs=[f'{index} C{i}'], axis=1)\n",
    "        graph_def.node.extend([concat_node])\n",
    "    \n",
    "    concat_node = helper.make_node('Concat', inputs=[f'{index} C{i}' for i in range(M_blocks)], outputs=[f'{index} output_wt_bias'], axis=0)\n",
    "    graph_def.node.extend([concat_node])\n",
    "\n",
    "    add_node = helper.make_node('Add', inputs=[f'{index} output_wt_bias', input_C_name], outputs=[output_name])\n",
    "    graph_def.node.extend([add_node])\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc8680d-c185-4bfc-b3f7-c494bfdf373f",
   "metadata": {},
   "source": [
    "### Build MY Alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c099d73a-1ed8-47b8-8601-3c3bafd4aa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_alexnet = onnx.helper.make_graph(\n",
    "    nodes=[],\n",
    "    name=\"my_alexnet\",\n",
    "    inputs=alexnet_model.graph.input,\n",
    "    outputs=alexnet_model.graph.output,\n",
    "    initializer=alexnet_model.graph.initializer,\n",
    ")\n",
    "\n",
    "Block_Size = 64\n",
    "\n",
    "for node in alexnet_model.graph.node:\n",
    "    if node.name == GEMM_Layer_names[0]:\n",
    "        M, N, K, BLOCK_SIZE = 1, 9216, 4096, Block_Size\n",
    "        input1, input2, input3 = GEMM_Layer_input_names[0]\n",
    "        output = GEMM_Layer_output_names[0][0]\n",
    "        Build_GEMM2(M, N, K, BLOCK_SIZE, 0, input1, input2, input3, output, my_alexnet)\n",
    "    \n",
    "    elif node.name == GEMM_Layer_names[1]:\n",
    "        M, N, K, BLOCK_SIZE = 1, 4096, 4096, Block_Size\n",
    "        input1, input2, input3 = GEMM_Layer_input_names[1]\n",
    "        output = GEMM_Layer_output_names[1][0]\n",
    "        Build_GEMM2(M, N, K, BLOCK_SIZE, 1, input1, input2, input3, output, my_alexnet)\n",
    "       \n",
    "    elif node.name == GEMM_Layer_names[2]:\n",
    "        M, N, K, BLOCK_SIZE = 1, 4096, 1000, Block_Size\n",
    "        input1, input2, input3 = GEMM_Layer_input_names[2]\n",
    "        output = GEMM_Layer_output_names[2][0]\n",
    "        Build_GEMM2(M, N, K, BLOCK_SIZE, 2, input1, input2, input3, output, my_alexnet)\n",
    "   \n",
    "    else:\n",
    "        my_alexnet.node.extend([node])\n",
    "\n",
    "# Create a new model with the modified graph\n",
    "modified_model = onnx.helper.make_model(my_alexnet)\n",
    "modified_model_path = \"./models/modified_alexnet.onnx\"\n",
    "onnx.save(modified_model, modified_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d803264-73df-4783-b155-155afacd950b",
   "metadata": {},
   "source": [
    "### Correctness Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a25313c8-5f28-48fc-aa1b-a2ab22f650c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_alexnet = onnx.load(\"./models/modified_alexnet.onnx\", load_external_data=False)\n",
    "onnx.checker.check_model(modified_alexnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "897b256d-bc28-400a-9bd1-7b5d153ffe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_session = ort.InferenceSession(\"./models/alexnet.onnx\")\n",
    "mod_onnx_session = ort.InferenceSession(\"./models/modified_alexnet.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "540252ef-895a-4a6e-80ec-06aac2551df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "(1, 1, 1000)\n"
     ]
    }
   ],
   "source": [
    "input_name = onnx_session.get_inputs()[0].name\n",
    "input = np.random.rand(1, 3, 224, 224).astype(np.float32)\n",
    "\n",
    "onnx_output = onnx_session.run(None, {input_name: input})\n",
    "mod_onnx_output = mod_onnx_session.run(None, {input_name: input})\n",
    "print(np.allclose(np.array(mod_onnx_output), np.array(onnx_output), atol = 1e-6))\n",
    "print(np.array(mod_onnx_output).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c579f653-2523-4776-82d7-5a0da34aff37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d0c727f-6300-4101-8a87-57555752f210",
   "metadata": {},
   "source": [
    "### Misunderstand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f34370-307e-4c65-bc27-75c0891ec902",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGEMMLayer(nn.Module):\n",
    "    def __init__(self, input_size, output_size, block_size=64):\n",
    "        super(MyGEMMLayer, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.block_size = block_size\n",
    "\n",
    "        #linear_layer = nn.Linear(input_size, output_size, bias=True)\n",
    "        #self.weight = nn.Parameter(linear_layer.weight.t())  # Transpose here\n",
    "        #self.bias = nn.Parameter(linear_layer.bias)\n",
    "        self.weight = torch.transpose(weight, 0, 1)\n",
    "        self.bias = bias\n",
    "    \n",
    "    def forward(self, x):\n",
    "        M, _ = x.size()\n",
    "        N = self.input_size\n",
    "        K = self.output_size\n",
    "        block_size = self.block_size\n",
    "        \n",
    "        # Reshape input and weight matrices into blocks\n",
    "        x_blocks = x.view(M // block_size, block_size, N // block_size, block_size)\n",
    "        weight_blocks = self.weight.view(N // block_size, block_size, K // block_size, block_size)\n",
    "\n",
    "        output = torch.zeros(M, K)\n",
    "\n",
    "        # Perform the 64x64x64 tensor multiplication iteratively\n",
    "        for i in range(M // block_size):\n",
    "            for k in range(K // block_size):\n",
    "                for j in range(N // block_size):\n",
    "                    output[i * block_size: (i + 1) * block_size, k * block_size: (k + 1) * block_size] += torch.matmul(\n",
    "                        x_blocks[i, :, j, :], weight_blocks[j, :, k, :]\n",
    "                    )\n",
    "        output += self.bias\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "x_size = 256\n",
    "input_size = 192\n",
    "output_size = 128\n",
    "\n",
    "# Generate random input tensor\n",
    "input_tensor = torch.randn(x_size, input_size)\n",
    "\n",
    "# test my layer with origin linear layer \n",
    "linear = nn.Linear(input_size, output_size)\n",
    "# extract weight and bias in linear layer\n",
    "weight = linear.weight\n",
    "bias = linear.bias\n",
    "print(weight.size())\n",
    "print(bias.size())\n",
    "weight = linear.weight\n",
    "bias = linear.bias\n",
    "\n",
    "output_tensor = linear(input_tensor)\n",
    "\n",
    "gemm_layer = MyGEMMLayer(input_size, output_size)\n",
    "output_tensor2 = gemm_layer(input_tensor)\n",
    "\n",
    "tolerance = 1e-5\n",
    "print(torch.allclose(torch.transpose(linear.weight, 0, 1), gemm_layer.weight, atol=tolerance))\n",
    "print(torch.allclose(linear.bias, gemm_layer.bias, atol=tolerance))\n",
    "print(torch.allclose(output_tensor, output_tensor2, atol=tolerance))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
