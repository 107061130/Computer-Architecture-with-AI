{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa41986d-564f-42d6-ab71-dfe834ae21d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import onnx\n",
    "from onnx import shape_inference\n",
    "import sys\n",
    "from tabulate import tabulate\n",
    "from onnx import onnx_ml_pb2 as xpb2\n",
    "import onnx.helper as helper\n",
    "from onnx import numpy_helper\n",
    "import numpy as np\n",
    "from onnx import TensorProto\n",
    "import onnxruntime as ort\n",
    "from torch import Tensor\n",
    "from torch.nn.parameter import Parameter, UninitializedParameter\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd86f918-ed86-4637-98e6-4c80c97163fa",
   "metadata": {},
   "source": [
    "### Origin Alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc7c8858-dcb3-4ac7-8eff-48ee805ddfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, 1000),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42c40e07-a4c1-4681-a2a7-acba63e97291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AlexNet()\n",
    "input_data = torch.randn(1, 3, 224, 224)  # Assuming batch size is 1\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e39049-bb8e-438c-8363-bff0632c3007",
   "metadata": {},
   "source": [
    "### My Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e097f119-a27e-4f61-99eb-4f93d00c45d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int, bias: bool = True) -> None:\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.empty((in_features, out_features)))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.empty(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "            \n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        M_blocks = (input.size(0) + Block_Size - 1) // Block_Size\n",
    "        N_blocks = (self.in_features + Block_Size - 1) // Block_Size\n",
    "        K_blocks = (self.out_features + Block_Size - 1) // Block_Size\n",
    "        \n",
    "        A_split_row = torch.split(input, split_size_or_sections=Block_Size, dim=0)\n",
    "        A_blocks = []\n",
    "        for A_row in A_split_row:\n",
    "            A_col = torch.split(A_row, split_size_or_sections=Block_Size, dim=1)\n",
    "            A_blocks.append(A_col)\n",
    "\n",
    "        B = self.weight\n",
    "        B_split_row = torch.split(self.weight, split_size_or_sections=Block_Size, dim=0)\n",
    "        B_blocks = []\n",
    "        for B_row in B_split_row:\n",
    "            B_col = torch.split(B_row, split_size_or_sections=Block_Size, dim=1)\n",
    "            B_blocks.append(B_col)\n",
    "        \n",
    "        matmul_blocks =  [[[0 for _ in range(N_blocks)] for _ in range(K_blocks)] for _ in range(M_blocks)]\n",
    "        for i in range(M_blocks):\n",
    "            for j in range(K_blocks):\n",
    "                for k in range(N_blocks):\n",
    "                    matmul_blocks[i][j][k] = torch.matmul(A_blocks[i][k], B_blocks[k][j])\n",
    "\n",
    "        C_blocks = [[0 for _ in range(K_blocks)] for _ in range(M_blocks)]\n",
    "        for i in range(M_blocks):\n",
    "            for j in range(K_blocks):\n",
    "                if (N_blocks == 1): \n",
    "                    C_blocks[i][j] = matmul_blocks[i][j][0]\n",
    "                else:\n",
    "                    temp = matmul_blocks[i][j]\n",
    "                    while (len(temp) > 2):\n",
    "                        temp.append(torch.add(temp[0], temp[1]))\n",
    "                        temp.pop(0)\n",
    "                        temp.pop(0)\n",
    "                    C_blocks[i][j] = torch.add(temp[0], temp[1])\n",
    "\n",
    "        C_row = []\n",
    "        for i in range(M_blocks):\n",
    "            C_row.append(torch.cat(C_blocks[i], dim=1))\n",
    "        C = torch.cat(C_row, dim=0)\n",
    "        OUT = torch.add(C, self.bias)\n",
    "        return OUT\n",
    "\n",
    "        \n",
    "    def extra_repr(self) -> str:\n",
    "        return f'in_features={self.in_features}, out_features={self.out_features}, bias={self.bias is not None}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070208ff-b943-41ae-b8e8-4d9d36c8bb15",
   "metadata": {},
   "source": [
    "### My Alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7b672e4-6546-41c1-b73f-1bf36acea678",
   "metadata": {},
   "outputs": [],
   "source": [
    "class modified_AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.mp1 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.conv2 = nn.Conv2d(64, 192, kernel_size=5, padding=2)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.mp2 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.conv3 = nn.Conv2d(192, 384, kernel_size=3, padding=1)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "        self.conv4 = nn.Conv2d(384, 256, kernel_size=3, padding=1)\n",
    "        self.relu4 = nn.ReLU(inplace=True)\n",
    "        self.conv5 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.relu5 = nn.ReLU(inplace=True)\n",
    "        self.mp3 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.flatten = nn.Flatten(1, -1)\n",
    "\n",
    "        self.dropout1 = nn.Dropout()\n",
    "        self.linear1 = MyLinear(9216, 4096)\n",
    "        self.relu6 = nn.ReLU(inplace=True)\n",
    "        self.linear2 = MyLinear(4096, 4096)\n",
    "        self.dropout2 = nn.Dropout()\n",
    "        self.relu7 = nn.ReLU(inplace=True)\n",
    "        self.linear3 = MyLinear(4096, 1000)\n",
    "            \n",
    "    def forward(self, x: torch.Tensor) ->torch.Tensor:\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.mp1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.mp2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.relu5(x)\n",
    "        x = self.mp3(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu6(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.relu7(x)\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8adc61ea-2ac3-4cc8-9a8f-b52670b9c7b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "modified_AlexNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "  (relu1): ReLU(inplace=True)\n",
       "  (mp1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (relu2): ReLU(inplace=True)\n",
       "  (mp2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu3): ReLU(inplace=True)\n",
       "  (conv4): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu4): ReLU(inplace=True)\n",
       "  (conv5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu5): ReLU(inplace=True)\n",
       "  (mp3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (dropout1): Dropout(p=0.5, inplace=False)\n",
       "  (linear1): MyLinear(in_features=9216, out_features=4096, bias=True)\n",
       "  (relu6): ReLU(inplace=True)\n",
       "  (linear2): MyLinear(in_features=4096, out_features=4096, bias=True)\n",
       "  (dropout2): Dropout(p=0.5, inplace=False)\n",
       "  (relu7): ReLU(inplace=True)\n",
       "  (linear3): MyLinear(in_features=4096, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Block_Size = 64\n",
    "modified_model = modified_AlexNet()\n",
    "input_data = torch.randn(1, 3, 224, 224)  # Assuming batch size is 1\n",
    "modified_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b9b34a-e708-4f71-8691-236204ae9f82",
   "metadata": {},
   "source": [
    "### Export to pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9333c82-d6e5-441a-af44-57b650115e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_script_module = torch.jit.trace(modified_model, input_data, check_trace=True)\n",
    "traced_script_module.save(\"./models/modified_alexnet_pytorch.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1fa88f9-9b8c-4712-9f65-3c508234e43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1000])\n"
     ]
    }
   ],
   "source": [
    "script_module = torch.jit.load('./models/modified_alexnet_pytorch.pt')\n",
    "output = script_module(input_data)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcd2470-674c-4ff8-b998-a4ac13ca5917",
   "metadata": {},
   "source": [
    "### Onnx Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa2a0ddf-a2be-4093-ad2f-d54a019e51e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class modified_AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        \n",
    "        #classifier\n",
    "        self.dropout1 = nn.Dropout()\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.dropout2 = nn.Dropout()\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.W1 = Parameter(torch.empty((9216, 4096)))\n",
    "        self.b1 = Parameter(torch.empty(4096))\n",
    "        self.W2 = Parameter(torch.empty((4096, 4096)))\n",
    "        self.b2 = Parameter(torch.empty(4096))\n",
    "        self.W3 = Parameter(torch.empty((4096, 1000)))\n",
    "        self.b3 = Parameter(torch.empty(1000))\n",
    "            \n",
    "    def Build_Mylinear_Layer(self, A: torch.Tensor, Block_Size: int, idx: int, M: int, N: int, K: int) ->torch.Tensor:\n",
    "        if (idx == 1):\n",
    "            B = self.W1\n",
    "            bias = self.b1\n",
    "        elif(idx == 2):\n",
    "            B = self.W2\n",
    "            bias = self.b2\n",
    "        else:\n",
    "            B = self.W3\n",
    "            bias = self.b3\n",
    "            \n",
    "        M_blocks = (M + Block_Size - 1) // Block_Size\n",
    "        N_blocks = (N + Block_Size - 1) // Block_Size\n",
    "        K_blocks = (K + Block_Size - 1) // Block_Size\n",
    "\n",
    "        A_split_row = torch.split(A, split_size_or_sections=Block_Size, dim=0)\n",
    "        A_blocks = []\n",
    "        for A_row in A_split_row:\n",
    "            A_col = torch.split(A_row, split_size_or_sections=Block_Size, dim=1)\n",
    "            A_blocks.append(A_col)\n",
    "            \n",
    "        B_split_row = torch.split(B, split_size_or_sections=Block_Size, dim=0)\n",
    "        B_blocks = []\n",
    "        for B_row in B_split_row:\n",
    "            B_col = torch.split(B_row, split_size_or_sections=Block_Size, dim=1)\n",
    "            B_blocks.append(B_col)\n",
    "        \n",
    "        matmul_blocks =  [[[0 for _ in range(N_blocks)] for _ in range(K_blocks)] for _ in range(M_blocks)]\n",
    "        for i in range(M_blocks):\n",
    "            for j in range(K_blocks):\n",
    "                for k in range(N_blocks):\n",
    "                    matmul_blocks[i][j][k] = torch.matmul(A_blocks[i][k], B_blocks[k][j])\n",
    "\n",
    "        C_blocks = [[0 for _ in range(K_blocks)] for _ in range(M_blocks)]\n",
    "        for i in range(M_blocks):\n",
    "            for j in range(K_blocks):\n",
    "                if (N_blocks == 1): \n",
    "                    C_blocks[i][j] = matmul_blocks[i][j][0]\n",
    "                else:\n",
    "                    temp = matmul_blocks[i][j]\n",
    "                    while (len(temp) > 2):\n",
    "                        temp.append(torch.add(temp[0], temp[1]))\n",
    "                        temp.pop(0)\n",
    "                        temp.pop(0)\n",
    "                    C_blocks[i][j] = torch.add(temp[0], temp[1])\n",
    "\n",
    "        C_row = []\n",
    "        for i in range(M_blocks):\n",
    "            C_row.append(torch.cat(C_blocks[i], dim=1))\n",
    "        C = torch.cat(C_row, dim=0)\n",
    "        OUT = torch.add(C, bias)\n",
    "        return OUT\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) ->torch.Tensor:\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.Build_Mylinear_Layer(x, Block_Size, 1, 1, 9216, 4096)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.Build_Mylinear_Layer(x, Block_Size, 2, 1, 4096, 4096)\n",
    "        x = self.relu2(x)\n",
    "        x = self.Build_Mylinear_Layer(x, Block_Size, 3, 1, 4096, 1000)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4df11020-a9d1-4d42-b39c-cd29a527e519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "modified_AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (dropout1): Dropout(p=0.5, inplace=False)\n",
       "  (relu1): ReLU(inplace=True)\n",
       "  (dropout2): Dropout(p=0.5, inplace=False)\n",
       "  (relu2): ReLU(inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Block_Size = 1024\n",
    "modified_model = modified_AlexNet()\n",
    "input_data = torch.randn(1, 3, 224, 224)  # Assuming batch size is 1\n",
    "modified_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dc1981-d348-41f3-bff6-0c790f00efc7",
   "metadata": {},
   "source": [
    "### Export to onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c63f2791-c71d-41e9-b969-00386386ad99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%actual_input_1 : Float(1, 3, 224, 224, strides=[150528, 50176, 224, 1], requires_grad=0, device=cpu),\n",
      "      %learned_10 : Float(9216, 4096, strides=[4096, 1], requires_grad=1, device=cpu),\n",
      "      %learned_11 : Float(4096, strides=[1], requires_grad=1, device=cpu),\n",
      "      %learned_12 : Float(4096, 4096, strides=[4096, 1], requires_grad=1, device=cpu),\n",
      "      %learned_13 : Float(4096, strides=[1], requires_grad=1, device=cpu),\n",
      "      %learned_14 : Float(4096, 1000, strides=[1000, 1], requires_grad=1, device=cpu),\n",
      "      %learned_15 : Float(1000, strides=[1], requires_grad=1, device=cpu),\n",
      "      %learned_0 : Float(64, 3, 11, 11, strides=[363, 121, 11, 1], requires_grad=1, device=cpu),\n",
      "      %learned_1 : Float(64, strides=[1], requires_grad=1, device=cpu),\n",
      "      %learned_2 : Float(192, 64, 5, 5, strides=[1600, 25, 5, 1], requires_grad=1, device=cpu),\n",
      "      %learned_3 : Float(192, strides=[1], requires_grad=1, device=cpu),\n",
      "      %learned_4 : Float(384, 192, 3, 3, strides=[1728, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %learned_5 : Float(384, strides=[1], requires_grad=1, device=cpu),\n",
      "      %learned_6 : Float(256, 384, 3, 3, strides=[3456, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %learned_7 : Float(256, strides=[1], requires_grad=1, device=cpu),\n",
      "      %learned_8 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %learned_9 : Float(256, strides=[1], requires_grad=1, device=cpu)):\n",
      "  %/features/features.0/Conv_output_0 : Float(1, 64, 55, 55, strides=[193600, 3025, 55, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[11, 11], pads=[2, 2, 2, 2], strides=[4, 4], onnx_name=\"/features/features.0/Conv\"](%actual_input_1, %learned_0, %learned_1), scope: __main__.modified_AlexNet::/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.0 # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/features/features.1/Relu_output_0 : Float(1, 64, 55, 55, strides=[193600, 3025, 55, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/features/features.1/Relu\"](%/features/features.0/Conv_output_0), scope: __main__.modified_AlexNet::/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.1 # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/nn/functional.py:1471:0\n",
      "  %/features/features.2/MaxPool_output_0 : Float(1, 64, 27, 27, strides=[46656, 729, 27, 1], requires_grad=1, device=cpu) = onnx::MaxPool[ceil_mode=0, dilations=[1, 1], kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/features/features.2/MaxPool\"](%/features/features.1/Relu_output_0), scope: __main__.modified_AlexNet::/torch.nn.modules.container.Sequential::features/torch.nn.modules.pooling.MaxPool2d::features.2 # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/nn/functional.py:796:0\n",
      "  %/features/features.3/Conv_output_0 : Float(1, 192, 27, 27, strides=[139968, 729, 27, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1], onnx_name=\"/features/features.3/Conv\"](%/features/features.2/MaxPool_output_0, %learned_2, %learned_3), scope: __main__.modified_AlexNet::/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.3 # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/features/features.4/Relu_output_0 : Float(1, 192, 27, 27, strides=[139968, 729, 27, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/features/features.4/Relu\"](%/features/features.3/Conv_output_0), scope: __main__.modified_AlexNet::/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.4 # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/nn/functional.py:1471:0\n",
      "  %/features/features.5/MaxPool_output_0 : Float(1, 192, 13, 13, strides=[32448, 169, 13, 1], requires_grad=1, device=cpu) = onnx::MaxPool[ceil_mode=0, dilations=[1, 1], kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/features/features.5/MaxPool\"](%/features/features.4/Relu_output_0), scope: __main__.modified_AlexNet::/torch.nn.modules.container.Sequential::features/torch.nn.modules.pooling.MaxPool2d::features.5 # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/nn/functional.py:796:0\n",
      "  %/features/features.6/Conv_output_0 : Float(1, 384, 13, 13, strides=[64896, 169, 13, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/features/features.6/Conv\"](%/features/features.5/MaxPool_output_0, %learned_4, %learned_5), scope: __main__.modified_AlexNet::/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.6 # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/features/features.7/Relu_output_0 : Float(1, 384, 13, 13, strides=[64896, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/features/features.7/Relu\"](%/features/features.6/Conv_output_0), scope: __main__.modified_AlexNet::/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.7 # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/nn/functional.py:1471:0\n",
      "  %/features/features.8/Conv_output_0 : Float(1, 256, 13, 13, strides=[43264, 169, 13, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/features/features.8/Conv\"](%/features/features.7/Relu_output_0, %learned_6, %learned_7), scope: __main__.modified_AlexNet::/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.8 # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/features/features.9/Relu_output_0 : Float(1, 256, 13, 13, strides=[43264, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/features/features.9/Relu\"](%/features/features.8/Conv_output_0), scope: __main__.modified_AlexNet::/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.9 # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/nn/functional.py:1471:0\n",
      "  %/features/features.10/Conv_output_0 : Float(1, 256, 13, 13, strides=[43264, 169, 13, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/features/features.10/Conv\"](%/features/features.9/Relu_output_0, %learned_8, %learned_9), scope: __main__.modified_AlexNet::/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.10 # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/features/features.11/Relu_output_0 : Float(1, 256, 13, 13, strides=[43264, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/features/features.11/Relu\"](%/features/features.10/Conv_output_0), scope: __main__.modified_AlexNet::/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.11 # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/nn/functional.py:1471:0\n",
      "  %/features/features.12/MaxPool_output_0 : Float(1, 256, 6, 6, strides=[9216, 36, 6, 1], requires_grad=1, device=cpu) = onnx::MaxPool[ceil_mode=0, dilations=[1, 1], kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/features/features.12/MaxPool\"](%/features/features.11/Relu_output_0), scope: __main__.modified_AlexNet::/torch.nn.modules.container.Sequential::features/torch.nn.modules.pooling.MaxPool2d::features.12 # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/nn/functional.py:796:0\n",
      "  %/avgpool/AveragePool_output_0 : Float(1, 256, 6, 6, strides=[9216, 36, 6, 1], requires_grad=1, device=cpu) = onnx::AveragePool[kernel_shape=[1, 1], strides=[1, 1], onnx_name=\"/avgpool/AveragePool\"](%/features/features.12/MaxPool_output_0), scope: __main__.modified_AlexNet::/torch.nn.modules.pooling.AdaptiveAvgPool2d::avgpool # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/nn/functional.py:1233:0\n",
      "  %/Flatten_output_0 : Float(1, 9216, strides=[9216, 1], requires_grad=1, device=cpu) = onnx::Flatten[axis=1, onnx_name=\"/Flatten\"](%/avgpool/AveragePool_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:89:0\n",
      "  %/Constant_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/Constant\"](), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Split_output_0 : Float(1, 9216, strides=[9216, 1], requires_grad=1, device=cpu) = onnx::Split[axis=0, onnx_name=\"/Split\"](%/Flatten_output_0, %/Constant_output_0), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Constant_1_output_0 : Long(9, strides=[1], device=cpu) = onnx::Constant[value= 1024  1024  1024  1024  1024  1024  1024  1024  1024 [ CPULongType{9} ], onnx_name=\"/Constant_1\"](), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Split_1_output_0 : Float(1, 1024, strides=[9216, 1], requires_grad=1, device=cpu), %/Split_1_output_1 : Float(1, 1024, strides=[9216, 1], requires_grad=1, device=cpu), %/Split_1_output_2 : Float(1, 1024, strides=[9216, 1], requires_grad=1, device=cpu), %/Split_1_output_3 : Float(1, 1024, strides=[9216, 1], requires_grad=1, device=cpu), %/Split_1_output_4 : Float(1, 1024, strides=[9216, 1], requires_grad=1, device=cpu), %/Split_1_output_5 : Float(1, 1024, strides=[9216, 1], requires_grad=1, device=cpu), %/Split_1_output_6 : Float(1, 1024, strides=[9216, 1], requires_grad=1, device=cpu), %/Split_1_output_7 : Float(1, 1024, strides=[9216, 1], requires_grad=1, device=cpu), %/Split_1_output_8 : Float(1, 1024, strides=[9216, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1, onnx_name=\"/Split_1\"](%/Split_output_0, %/Constant_1_output_0), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Constant_2_output_0 : Long(9, strides=[1], device=cpu) = onnx::Constant[value= 1024  1024  1024  1024  1024  1024  1024  1024  1024 [ CPULongType{9} ], onnx_name=\"/Constant_2\"](), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Split_2_output_0 : Float(1024, 4096, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_2_output_1 : Float(1024, 4096, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_2_output_2 : Float(1024, 4096, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_2_output_3 : Float(1024, 4096, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_2_output_4 : Float(1024, 4096, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_2_output_5 : Float(1024, 4096, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_2_output_6 : Float(1024, 4096, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_2_output_7 : Float(1024, 4096, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_2_output_8 : Float(1024, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Split[axis=0, onnx_name=\"/Split_2\"](%learned_10, %/Constant_2_output_0), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Constant_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 1024  1024  1024  1024 [ CPULongType{4} ], onnx_name=\"/Constant_3\"](), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Split_3_output_0 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_3_output_1 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_3_output_2 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_3_output_3 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1, onnx_name=\"/Split_3\"](%/Split_2_output_0, %/Constant_3_output_0), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Constant_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 1024  1024  1024  1024 [ CPULongType{4} ], onnx_name=\"/Constant_4\"](), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Split_4_output_0 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_4_output_1 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_4_output_2 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_4_output_3 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1, onnx_name=\"/Split_4\"](%/Split_2_output_1, %/Constant_4_output_0), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Constant_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 1024  1024  1024  1024 [ CPULongType{4} ], onnx_name=\"/Constant_5\"](), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Split_5_output_0 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_5_output_1 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_5_output_2 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_5_output_3 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1, onnx_name=\"/Split_5\"](%/Split_2_output_2, %/Constant_5_output_0), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Constant_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 1024  1024  1024  1024 [ CPULongType{4} ], onnx_name=\"/Constant_6\"](), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Split_6_output_0 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_6_output_1 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_6_output_2 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_6_output_3 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1, onnx_name=\"/Split_6\"](%/Split_2_output_3, %/Constant_6_output_0), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Constant_7_output_0 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 1024  1024  1024  1024 [ CPULongType{4} ], onnx_name=\"/Constant_7\"](), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Split_7_output_0 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_7_output_1 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_7_output_2 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_7_output_3 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1, onnx_name=\"/Split_7\"](%/Split_2_output_4, %/Constant_7_output_0), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Constant_8_output_0 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 1024  1024  1024  1024 [ CPULongType{4} ], onnx_name=\"/Constant_8\"](), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Split_8_output_0 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_8_output_1 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_8_output_2 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_8_output_3 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1, onnx_name=\"/Split_8\"](%/Split_2_output_5, %/Constant_8_output_0), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Constant_9_output_0 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 1024  1024  1024  1024 [ CPULongType{4} ], onnx_name=\"/Constant_9\"](), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Split_9_output_0 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_9_output_1 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_9_output_2 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_9_output_3 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1, onnx_name=\"/Split_9\"](%/Split_2_output_6, %/Constant_9_output_0), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Constant_10_output_0 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 1024  1024  1024  1024 [ CPULongType{4} ], onnx_name=\"/Constant_10\"](), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Split_10_output_0 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_10_output_1 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_10_output_2 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_10_output_3 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1, onnx_name=\"/Split_10\"](%/Split_2_output_7, %/Constant_10_output_0), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Constant_11_output_0 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 1024  1024  1024  1024 [ CPULongType{4} ], onnx_name=\"/Constant_11\"](), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Split_11_output_0 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_11_output_1 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_11_output_2 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_11_output_3 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1, onnx_name=\"/Split_11\"](%/Split_2_output_8, %/Constant_11_output_0), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/MatMul_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul\"](%/Split_1_output_0, %/Split_3_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_1_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_1\"](%/Split_1_output_1, %/Split_4_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_2_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_2\"](%/Split_1_output_2, %/Split_5_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_3_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_3\"](%/Split_1_output_3, %/Split_6_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_4_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_4\"](%/Split_1_output_4, %/Split_7_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_5_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_5\"](%/Split_1_output_5, %/Split_8_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_6_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_6\"](%/Split_1_output_6, %/Split_9_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_7_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_7\"](%/Split_1_output_7, %/Split_10_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_8_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_8\"](%/Split_1_output_8, %/Split_11_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_9_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_9\"](%/Split_1_output_0, %/Split_3_output_1), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_10_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_10\"](%/Split_1_output_1, %/Split_4_output_1), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_11_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_11\"](%/Split_1_output_2, %/Split_5_output_1), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_12_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_12\"](%/Split_1_output_3, %/Split_6_output_1), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_13_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_13\"](%/Split_1_output_4, %/Split_7_output_1), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_14_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_14\"](%/Split_1_output_5, %/Split_8_output_1), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_15_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_15\"](%/Split_1_output_6, %/Split_9_output_1), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_16_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_16\"](%/Split_1_output_7, %/Split_10_output_1), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_17_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_17\"](%/Split_1_output_8, %/Split_11_output_1), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_18_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_18\"](%/Split_1_output_0, %/Split_3_output_2), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_19_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_19\"](%/Split_1_output_1, %/Split_4_output_2), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_20_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_20\"](%/Split_1_output_2, %/Split_5_output_2), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_21_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_21\"](%/Split_1_output_3, %/Split_6_output_2), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_22_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_22\"](%/Split_1_output_4, %/Split_7_output_2), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_23_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_23\"](%/Split_1_output_5, %/Split_8_output_2), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_24_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_24\"](%/Split_1_output_6, %/Split_9_output_2), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_25_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_25\"](%/Split_1_output_7, %/Split_10_output_2), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_26_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_26\"](%/Split_1_output_8, %/Split_11_output_2), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_27_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_27\"](%/Split_1_output_0, %/Split_3_output_3), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_28_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_28\"](%/Split_1_output_1, %/Split_4_output_3), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_29_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_29\"](%/Split_1_output_2, %/Split_5_output_3), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_30_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_30\"](%/Split_1_output_3, %/Split_6_output_3), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_31_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_31\"](%/Split_1_output_4, %/Split_7_output_3), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_32_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_32\"](%/Split_1_output_5, %/Split_8_output_3), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_33_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_33\"](%/Split_1_output_6, %/Split_9_output_3), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_34_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_34\"](%/Split_1_output_7, %/Split_10_output_3), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_35_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_35\"](%/Split_1_output_8, %/Split_11_output_3), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/Add_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add\"](%/MatMul_output_0, %/MatMul_1_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:74:0\n",
      "  %/Add_1_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_1\"](%/MatMul_2_output_0, %/MatMul_3_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:74:0\n",
      "  %/Add_2_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_2\"](%/MatMul_4_output_0, %/MatMul_5_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:74:0\n",
      "  %/Add_3_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_3\"](%/MatMul_6_output_0, %/MatMul_7_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:74:0\n",
      "  %/Add_4_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_4\"](%/MatMul_8_output_0, %/Add_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:74:0\n",
      "  %/Add_5_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_5\"](%/Add_1_output_0, %/Add_2_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:74:0\n",
      "  %/Add_6_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_6\"](%/Add_3_output_0, %/Add_4_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:74:0\n",
      "  %/Add_7_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_7\"](%/Add_5_output_0, %/Add_6_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:77:0\n",
      "  %/Add_8_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_8\"](%/MatMul_9_output_0, %/MatMul_10_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:74:0\n",
      "  %/Add_9_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_9\"](%/MatMul_11_output_0, %/MatMul_12_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:74:0\n",
      "  %/Add_10_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_10\"](%/MatMul_13_output_0, %/MatMul_14_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:74:0\n",
      "  %/Add_11_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_11\"](%/MatMul_15_output_0, %/MatMul_16_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:74:0\n",
      "  %/Add_12_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_12\"](%/MatMul_17_output_0, %/Add_8_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:74:0\n",
      "  %/Add_13_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_13\"](%/Add_9_output_0, %/Add_10_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:74:0\n",
      "  %/Add_14_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_14\"](%/Add_11_output_0, %/Add_12_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:74:0\n",
      "  %/Add_15_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_15\"](%/Add_13_output_0, %/Add_14_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:77:0\n",
      "  %/Add_16_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_16\"](%/MatMul_18_output_0, %/MatMul_19_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:74:0\n",
      "  %/Add_17_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_17\"](%/MatMul_20_output_0, %/MatMul_21_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:74:0\n",
      "  %/Add_18_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_18\"](%/MatMul_22_output_0, %/MatMul_23_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:74:0\n",
      "  %/Add_19_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_19\"](%/MatMul_24_output_0, %/MatMul_25_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:74:0\n",
      "  %/Add_20_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_20\"](%/MatMul_26_output_0, %/Add_16_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:74:0\n",
      "  %/Add_21_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_21\"](%/Add_17_output_0, %/Add_18_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:74:0\n",
      "  %/Add_22_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_22\"](%/Add_19_output_0, %/Add_20_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:74:0\n",
      "  %/Add_23_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_23\"](%/Add_21_output_0, %/Add_22_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:77:0\n",
      "  %/Add_24_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_24\"](%/MatMul_27_output_0, %/MatMul_28_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:74:0\n",
      "  %/Add_25_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_25\"](%/MatMul_29_output_0, %/MatMul_30_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:74:0\n",
      "  %/Add_26_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_26\"](%/MatMul_31_output_0, %/MatMul_32_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:74:0\n",
      "  %/Add_27_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_27\"](%/MatMul_33_output_0, %/MatMul_34_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:74:0\n",
      "  %/Add_28_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_28\"](%/MatMul_35_output_0, %/Add_24_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:74:0\n",
      "  %/Add_29_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_29\"](%/Add_25_output_0, %/Add_26_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:74:0\n",
      "  %/Add_30_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_30\"](%/Add_27_output_0, %/Add_28_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:74:0\n",
      "  %/Add_31_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_31\"](%/Add_29_output_0, %/Add_30_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:77:0\n",
      "  %/Concat_output_0 : Float(1, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/Concat\"](%/Add_7_output_0, %/Add_15_output_0, %/Add_23_output_0, %/Add_31_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:81:0\n",
      "  %/Concat_1_output_0 : Float(1, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=0, onnx_name=\"/Concat_1\"](%/Concat_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:82:0\n",
      "  %/Add_32_output_0 : Float(1, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_32\"](%/Concat_1_output_0, %learned_11), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:83:0\n",
      "  %/relu1/Relu_output_0 : Float(1, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/relu1/Relu\"](%/Add_32_output_0), scope: __main__.modified_AlexNet::/torch.nn.modules.activation.ReLU::relu1 # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/nn/functional.py:1471:0\n",
      "  %/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/Constant_12\"](), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Split_12_output_0 : Float(1, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Split[axis=0, onnx_name=\"/Split_12\"](%/relu1/Relu_output_0, %/Constant_12_output_0), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Constant_13_output_0 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 1024  1024  1024  1024 [ CPULongType{4} ], onnx_name=\"/Constant_13\"](), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Split_13_output_0 : Float(1, 1024, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_13_output_1 : Float(1, 1024, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_13_output_2 : Float(1, 1024, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_13_output_3 : Float(1, 1024, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1, onnx_name=\"/Split_13\"](%/Split_12_output_0, %/Constant_13_output_0), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Constant_14_output_0 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 1024  1024  1024  1024 [ CPULongType{4} ], onnx_name=\"/Constant_14\"](), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Split_14_output_0 : Float(1024, 4096, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_14_output_1 : Float(1024, 4096, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_14_output_2 : Float(1024, 4096, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_14_output_3 : Float(1024, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Split[axis=0, onnx_name=\"/Split_14\"](%learned_12, %/Constant_14_output_0), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Constant_15_output_0 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 1024  1024  1024  1024 [ CPULongType{4} ], onnx_name=\"/Constant_15\"](), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Split_15_output_0 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_15_output_1 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_15_output_2 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_15_output_3 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1, onnx_name=\"/Split_15\"](%/Split_14_output_0, %/Constant_15_output_0), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Constant_16_output_0 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 1024  1024  1024  1024 [ CPULongType{4} ], onnx_name=\"/Constant_16\"](), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Split_16_output_0 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_16_output_1 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_16_output_2 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_16_output_3 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1, onnx_name=\"/Split_16\"](%/Split_14_output_1, %/Constant_16_output_0), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Constant_17_output_0 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 1024  1024  1024  1024 [ CPULongType{4} ], onnx_name=\"/Constant_17\"](), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Split_17_output_0 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_17_output_1 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_17_output_2 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_17_output_3 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1, onnx_name=\"/Split_17\"](%/Split_14_output_2, %/Constant_17_output_0), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Constant_18_output_0 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 1024  1024  1024  1024 [ CPULongType{4} ], onnx_name=\"/Constant_18\"](), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Split_18_output_0 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_18_output_1 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_18_output_2 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_18_output_3 : Float(1024, 1024, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1, onnx_name=\"/Split_18\"](%/Split_14_output_3, %/Constant_18_output_0), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/MatMul_36_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_36\"](%/Split_13_output_0, %/Split_15_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_37_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_37\"](%/Split_13_output_1, %/Split_16_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_38_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_38\"](%/Split_13_output_2, %/Split_17_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_39_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_39\"](%/Split_13_output_3, %/Split_18_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_40_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_40\"](%/Split_13_output_0, %/Split_15_output_1), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_41_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_41\"](%/Split_13_output_1, %/Split_16_output_1), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_42_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_42\"](%/Split_13_output_2, %/Split_17_output_1), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_43_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_43\"](%/Split_13_output_3, %/Split_18_output_1), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_44_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_44\"](%/Split_13_output_0, %/Split_15_output_2), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_45_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_45\"](%/Split_13_output_1, %/Split_16_output_2), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_46_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_46\"](%/Split_13_output_2, %/Split_17_output_2), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_47_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_47\"](%/Split_13_output_3, %/Split_18_output_2), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_48_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_48\"](%/Split_13_output_0, %/Split_15_output_3), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_49_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_49\"](%/Split_13_output_1, %/Split_16_output_3), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_50_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_50\"](%/Split_13_output_2, %/Split_17_output_3), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_51_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_51\"](%/Split_13_output_3, %/Split_18_output_3), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/Add_33_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_33\"](%/MatMul_36_output_0, %/MatMul_37_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:74:0\n",
      "  %/Add_34_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_34\"](%/MatMul_38_output_0, %/MatMul_39_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:74:0\n",
      "  %/Add_35_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_35\"](%/Add_33_output_0, %/Add_34_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:77:0\n",
      "  %/Add_36_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_36\"](%/MatMul_40_output_0, %/MatMul_41_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:74:0\n",
      "  %/Add_37_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_37\"](%/MatMul_42_output_0, %/MatMul_43_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:74:0\n",
      "  %/Add_38_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_38\"](%/Add_36_output_0, %/Add_37_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:77:0\n",
      "  %/Add_39_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_39\"](%/MatMul_44_output_0, %/MatMul_45_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:74:0\n",
      "  %/Add_40_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_40\"](%/MatMul_46_output_0, %/MatMul_47_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:74:0\n",
      "  %/Add_41_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_41\"](%/Add_39_output_0, %/Add_40_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:77:0\n",
      "  %/Add_42_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_42\"](%/MatMul_48_output_0, %/MatMul_49_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:74:0\n",
      "  %/Add_43_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_43\"](%/MatMul_50_output_0, %/MatMul_51_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:74:0\n",
      "  %/Add_44_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_44\"](%/Add_42_output_0, %/Add_43_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:77:0\n",
      "  %/Concat_2_output_0 : Float(1, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/Concat_2\"](%/Add_35_output_0, %/Add_38_output_0, %/Add_41_output_0, %/Add_44_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:81:0\n",
      "  %/Concat_3_output_0 : Float(1, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=0, onnx_name=\"/Concat_3\"](%/Concat_2_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:82:0\n",
      "  %/Add_45_output_0 : Float(1, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_45\"](%/Concat_3_output_0, %learned_13), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:83:0\n",
      "  %/relu2/Relu_output_0 : Float(1, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/relu2/Relu\"](%/Add_45_output_0), scope: __main__.modified_AlexNet::/torch.nn.modules.activation.ReLU::relu2 # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/nn/functional.py:1471:0\n",
      "  %/Constant_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/Constant_19\"](), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Split_19_output_0 : Float(1, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Split[axis=0, onnx_name=\"/Split_19\"](%/relu2/Relu_output_0, %/Constant_19_output_0), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Constant_20_output_0 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 1024  1024  1024  1024 [ CPULongType{4} ], onnx_name=\"/Constant_20\"](), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Split_20_output_0 : Float(1, 1024, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_20_output_1 : Float(1, 1024, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_20_output_2 : Float(1, 1024, strides=[4096, 1], requires_grad=1, device=cpu), %/Split_20_output_3 : Float(1, 1024, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1, onnx_name=\"/Split_20\"](%/Split_19_output_0, %/Constant_20_output_0), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Constant_21_output_0 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 1024  1024  1024  1024 [ CPULongType{4} ], onnx_name=\"/Constant_21\"](), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Split_21_output_0 : Float(1024, 1000, strides=[1000, 1], requires_grad=1, device=cpu), %/Split_21_output_1 : Float(1024, 1000, strides=[1000, 1], requires_grad=1, device=cpu), %/Split_21_output_2 : Float(1024, 1000, strides=[1000, 1], requires_grad=1, device=cpu), %/Split_21_output_3 : Float(1024, 1000, strides=[1000, 1], requires_grad=1, device=cpu) = onnx::Split[axis=0, onnx_name=\"/Split_21\"](%learned_14, %/Constant_21_output_0), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1000}, onnx_name=\"/Constant_22\"](), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Split_22_output_0 : Float(1024, 1000, strides=[1000, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1, onnx_name=\"/Split_22\"](%/Split_21_output_0, %/Constant_22_output_0), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Constant_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1000}, onnx_name=\"/Constant_23\"](), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Split_23_output_0 : Float(1024, 1000, strides=[1000, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1, onnx_name=\"/Split_23\"](%/Split_21_output_1, %/Constant_23_output_0), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Constant_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1000}, onnx_name=\"/Constant_24\"](), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Split_24_output_0 : Float(1024, 1000, strides=[1000, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1, onnx_name=\"/Split_24\"](%/Split_21_output_2, %/Constant_24_output_0), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Constant_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1000}, onnx_name=\"/Constant_25\"](), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/Split_25_output_0 : Float(1024, 1000, strides=[1000, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1, onnx_name=\"/Split_25\"](%/Split_21_output_3, %/Constant_25_output_0), scope: __main__.modified_AlexNet:: # /opt/conda/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:894:0\n",
      "  %/MatMul_52_output_0 : Float(1, 1000, strides=[1000, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_52\"](%/Split_20_output_0, %/Split_22_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_53_output_0 : Float(1, 1000, strides=[1000, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_53\"](%/Split_20_output_1, %/Split_23_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_54_output_0 : Float(1, 1000, strides=[1000, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_54\"](%/Split_20_output_2, %/Split_24_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/MatMul_55_output_0 : Float(1, 1000, strides=[1000, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_55\"](%/Split_20_output_3, %/Split_25_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:64:0\n",
      "  %/Add_46_output_0 : Float(1, 1000, strides=[1000, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_46\"](%/MatMul_52_output_0, %/MatMul_53_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:74:0\n",
      "  %/Add_47_output_0 : Float(1, 1000, strides=[1000, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_47\"](%/MatMul_54_output_0, %/MatMul_55_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:74:0\n",
      "  %/Add_48_output_0 : Float(1, 1000, strides=[1000, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_48\"](%/Add_46_output_0, %/Add_47_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:77:0\n",
      "  %/Concat_4_output_0 : Float(1, 1000, strides=[1000, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/Concat_4\"](%/Add_48_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:81:0\n",
      "  %/Concat_5_output_0 : Float(1, 1000, strides=[1000, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=0, onnx_name=\"/Concat_5\"](%/Concat_4_output_0), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:82:0\n",
      "  %output1 : Float(1, 1000, strides=[1000, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_49\"](%/Concat_5_output_0, %learned_15), scope: __main__.modified_AlexNet:: # /tmp/ipykernel_14817/280994955.py:83:0\n",
      "  return (%output1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create some sample input in the shape this model expects\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# It's optional to label the input and output layers\n",
    "input_names = [ \"actual_input_1\" ] + [ \"learned_%d\" % ((i+10)%16) for i in range(16) ]\n",
    "#input_names = [ \"actual_input_1\" ] + [ \"learned_%d\" % i for i in range(16) ]\n",
    "output_names = [ \"output1\" ]\n",
    "\n",
    "# Use the exporter from torch to convert to onnx \n",
    "# model (that has the weights and net arch)\n",
    "torch.onnx.export(modified_model, dummy_input, \"./models/modified_alexnet_pytorch.onnx\", verbose=True, input_names=input_names, output_names=output_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32551e3f-004d-4984-bb1c-484cfea5ed7c",
   "metadata": {},
   "source": [
    "### Check with onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d97c64c-7f2e-401e-bed2-b28c7d285a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = onnx.load(\"./models/modified_alexnet_pytorch.onnx\", load_external_data=False)\n",
    "onnx.checker.check_model(onnx_model)\n",
    "onnx_session = ort.InferenceSession(\"./models/modified_alexnet_pytorch.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dcf5e0-78c7-4c71-a2c4-163051d5a2e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
