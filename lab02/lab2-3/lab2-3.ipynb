{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 2-3. Parse an AI Model to Extract Model Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/ONNC/onnc-tutorial/raw/master/models/lenet/lenet.onnx "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ONNX format stores an model graph as a protobuf structure and and it can be accessed using the standard protobuf protocol APIs. Protocol buffers are Googleâ€™s language-neutral, platform-neutral, extensible mechanism for serializing structured data. You define how you want your data to be structured once, then you can use special generated source code to easily write and read your structured data to and from a variety of data streams and using a variety of languages. In this section, we will use the Python API to process an ONNX model as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "onnx_model = onnx.load('./lenet.onnx')\n",
    "\n",
    "# The model is represented as a protobuf structure and it can be accessed\n",
    "# using the standard python-for-protobuf methods\n",
    "\n",
    "## list all the operator types in the model\n",
    "node_list = []\n",
    "count = []\n",
    "for i in onnx_model.graph.node:\n",
    "    if (i.op_type not in node_list):\n",
    "        node_list.append(i.op_type)\n",
    "        count.append(1)\n",
    "    else:\n",
    "        idx = node_list.index(i.op_type)\n",
    "        count[idx] = count[idx]+1\n",
    "print(node_list)\n",
    "print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find the IR version\n",
    "print(onnx_model.ir_version)\n",
    "\n",
    "## find the computation graph\n",
    "print(onnx_model.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find the number of inputs\n",
    "print(len(onnx_model.graph.input))\n",
    "\n",
    "## find the number of nodes in the graph\n",
    "print(len(onnx_model.graph.node))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: \"import/Placeholder:0\"\n",
      "input: \"import/conv1first/Variable:0\"\n",
      "output: \"import/conv1first/Conv2D:0\"\n",
      "name: \"import/conv1first/Conv2D\"\n",
      "op_type: \"Conv\"\n",
      "attribute {\n",
      "  name: \"dilations\"\n",
      "  ints: 1\n",
      "  ints: 1\n",
      "  type: INTS\n",
      "}\n",
      "attribute {\n",
      "  name: \"strides\"\n",
      "  ints: 1\n",
      "  ints: 1\n",
      "  type: INTS\n",
      "}\n",
      "attribute {\n",
      "  name: \"kernel_shape\"\n",
      "  ints: 5\n",
      "  ints: 5\n",
      "  type: INTS\n",
      "}\n",
      "attribute {\n",
      "  name: \"pads\"\n",
      "  ints: 2\n",
      "  ints: 2\n",
      "  ints: 2\n",
      "  ints: 2\n",
      "  type: INTS\n",
      "}\n",
      "\n",
      "input: \"import/pool1/MaxPool:0\"\n",
      "input: \"import/conv2/Variable:0\"\n",
      "output: \"import/conv2/Conv2D:0\"\n",
      "name: \"import/conv2/Conv2D\"\n",
      "op_type: \"Conv\"\n",
      "attribute {\n",
      "  name: \"dilations\"\n",
      "  ints: 1\n",
      "  ints: 1\n",
      "  type: INTS\n",
      "}\n",
      "attribute {\n",
      "  name: \"strides\"\n",
      "  ints: 1\n",
      "  ints: 1\n",
      "  type: INTS\n",
      "}\n",
      "attribute {\n",
      "  name: \"kernel_shape\"\n",
      "  ints: 5\n",
      "  ints: 5\n",
      "  type: INTS\n",
      "}\n",
      "attribute {\n",
      "  name: \"pads\"\n",
      "  ints: 2\n",
      "  ints: 2\n",
      "  ints: 2\n",
      "  ints: 2\n",
      "  type: INTS\n",
      "}\n",
      "\n",
      "input: \"import/pool2/MaxPool:0\"\n",
      "input: \"import/conv3/Variable:0\"\n",
      "output: \"import/conv3/Conv2D:0\"\n",
      "name: \"import/conv3/Conv2D\"\n",
      "op_type: \"Conv\"\n",
      "attribute {\n",
      "  name: \"dilations\"\n",
      "  ints: 1\n",
      "  ints: 1\n",
      "  type: INTS\n",
      "}\n",
      "attribute {\n",
      "  name: \"strides\"\n",
      "  ints: 1\n",
      "  ints: 1\n",
      "  type: INTS\n",
      "}\n",
      "attribute {\n",
      "  name: \"kernel_shape\"\n",
      "  ints: 7\n",
      "  ints: 7\n",
      "  type: INTS\n",
      "}\n",
      "\n",
      "input: \"import/conv3/Relu:0\"\n",
      "input: \"import/conv4last/Variable:0\"\n",
      "output: \"import/conv4last/Conv2D:0\"\n",
      "name: \"import/conv4last/Conv2D\"\n",
      "op_type: \"Conv\"\n",
      "attribute {\n",
      "  name: \"dilations\"\n",
      "  ints: 1\n",
      "  ints: 1\n",
      "  type: INTS\n",
      "}\n",
      "attribute {\n",
      "  name: \"strides\"\n",
      "  ints: 1\n",
      "  ints: 1\n",
      "  type: INTS\n",
      "}\n",
      "attribute {\n",
      "  name: \"kernel_shape\"\n",
      "  ints: 1\n",
      "  ints: 1\n",
      "  type: INTS\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "onnx_model = onnx.load('./lenet.onnx')\n",
    "for i in onnx_model.graph.node:\n",
    "    if (i.op_type == 'Conv'):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab 2-3-1. Extract Input Information From an ONNX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: \"import/Placeholder:0\"\n",
      "input: \"import/conv1first/Variable:0\"\n",
      "output: \"import/conv1first/Conv2D:0\"\n",
      "name: \"import/conv1first/Conv2D\"\n",
      "op_type: \"Conv\"\n",
      "attribute {\n",
      "  name: \"dilations\"\n",
      "  ints: 1\n",
      "  ints: 1\n",
      "  type: INTS\n",
      "}\n",
      "attribute {\n",
      "  name: \"strides\"\n",
      "  ints: 1\n",
      "  ints: 1\n",
      "  type: INTS\n",
      "}\n",
      "attribute {\n",
      "  name: \"kernel_shape\"\n",
      "  ints: 5\n",
      "  ints: 5\n",
      "  type: INTS\n",
      "}\n",
      "attribute {\n",
      "  name: \"pads\"\n",
      "  ints: 2\n",
      "  ints: 2\n",
      "  ints: 2\n",
      "  ints: 2\n",
      "  type: INTS\n",
      "}\n",
      "\n",
      "input: \"import/pool1/MaxPool:0\"\n",
      "input: \"import/conv2/Variable:0\"\n",
      "output: \"import/conv2/Conv2D:0\"\n",
      "name: \"import/conv2/Conv2D\"\n",
      "op_type: \"Conv\"\n",
      "attribute {\n",
      "  name: \"dilations\"\n",
      "  ints: 1\n",
      "  ints: 1\n",
      "  type: INTS\n",
      "}\n",
      "attribute {\n",
      "  name: \"strides\"\n",
      "  ints: 1\n",
      "  ints: 1\n",
      "  type: INTS\n",
      "}\n",
      "attribute {\n",
      "  name: \"kernel_shape\"\n",
      "  ints: 5\n",
      "  ints: 5\n",
      "  type: INTS\n",
      "}\n",
      "attribute {\n",
      "  name: \"pads\"\n",
      "  ints: 2\n",
      "  ints: 2\n",
      "  ints: 2\n",
      "  ints: 2\n",
      "  type: INTS\n",
      "}\n",
      "\n",
      "input: \"import/pool2/MaxPool:0\"\n",
      "input: \"import/conv3/Variable:0\"\n",
      "output: \"import/conv3/Conv2D:0\"\n",
      "name: \"import/conv3/Conv2D\"\n",
      "op_type: \"Conv\"\n",
      "attribute {\n",
      "  name: \"dilations\"\n",
      "  ints: 1\n",
      "  ints: 1\n",
      "  type: INTS\n",
      "}\n",
      "attribute {\n",
      "  name: \"strides\"\n",
      "  ints: 1\n",
      "  ints: 1\n",
      "  type: INTS\n",
      "}\n",
      "attribute {\n",
      "  name: \"kernel_shape\"\n",
      "  ints: 7\n",
      "  ints: 7\n",
      "  type: INTS\n",
      "}\n",
      "\n",
      "input: \"import/conv3/Relu:0\"\n",
      "input: \"import/conv4last/Variable:0\"\n",
      "output: \"import/conv4last/Conv2D:0\"\n",
      "name: \"import/conv4last/Conv2D\"\n",
      "op_type: \"Conv\"\n",
      "attribute {\n",
      "  name: \"dilations\"\n",
      "  ints: 1\n",
      "  ints: 1\n",
      "  type: INTS\n",
      "}\n",
      "attribute {\n",
      "  name: \"strides\"\n",
      "  ints: 1\n",
      "  ints: 1\n",
      "  type: INTS\n",
      "}\n",
      "attribute {\n",
      "  name: \"kernel_shape\"\n",
      "  ints: 1\n",
      "  ints: 1\n",
      "  type: INTS\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "onnx_model = onnx.load('./lenet.onnx')\n",
    "for i in onnx_model.graph.node:\n",
    "    if (i.op_type == 'Conv'):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most DNN models spend a significant time in the Conv operators, likely to be around 60%~90%. To estimate the inference time, we need to figure out the toal number of multiply operations of all Conv operators required in a model. Do you know how to calculate the number of required number of multiply operations of all Conv operators in an ONNX model? We will give you a hint here and ask you to implement a script to generate the statistics in the homework section. The next script demonstrate how to figure out the input tensor sizes and dimensions of a Conv operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "input list: ['import/Placeholder:0', 'import/conv3/BiasAdd__19', 'import/conv3/Variable_1:0', 'import/conv2/Variable_1:0', 'import/conv4last/Variable_1:0', 'import/conv1first/Variable_1:0', 'import/conv3/Variable:0', 'import/conv4last/BiasAdd__21', 'import/conv2/Variable:0', 'import/conv4last/Variable:0', 'import/conv1first/BiasAdd__15', 'import/conv1first/Variable:0', 'import/conv2/BiasAdd__17']\n",
      "\n",
      "initializer list: ['import/conv3/BiasAdd__19', 'import/conv3/Variable_1:0', 'import/conv2/Variable_1:0', 'import/conv4last/Variable_1:0', 'import/conv1first/Variable_1:0', 'import/conv3/Variable:0', 'import/conv4last/BiasAdd__21', 'import/conv2/Variable:0', 'import/conv4last/Variable:0', 'import/conv1first/BiasAdd__15', 'import/conv1first/Variable:0', 'import/conv2/BiasAdd__17']\n",
      "\n",
      "value_info list: ['import/conv4last/BiasAdd__22:0', 'import/conv1first/BiasAdd__16:0', 'import/conv3/BiasAdd__20:0', 'import/conv2/BiasAdd__18:0', 'import/conv1first/Conv2D:0', 'import/conv1first/BiasAdd:0', 'import/conv1first/Relu:0', 'import/pool1/MaxPool:0', 'import/conv2/Conv2D:0', 'import/conv2/BiasAdd:0', 'import/conv2/Relu:0', 'import/pool2/MaxPool:0', 'import/conv3/Conv2D:0', 'import/conv3/BiasAdd:0', 'import/conv3/Relu:0', 'import/conv4last/Conv2D:0', 'raw_output___13:0']\n",
      "\n",
      "-- Conv \"import/conv1first/Conv2D\" --\n",
      "input import/Placeholder:0 has 784 elements dims = [1, 1, 28, 28]\n",
      "input import/conv1first/Variable:0 has 800 elements dims = [32, 1, 5, 5]\n",
      "\n",
      "-- Conv \"import/conv2/Conv2D\" --\n",
      "input import/pool1/MaxPool:0 has 6272 elements dims = [1, 32, 14, 14]\n",
      "input import/conv2/Variable:0 has 51200 elements dims = [64, 32, 5, 5]\n",
      "\n",
      "-- Conv \"import/conv3/Conv2D\" --\n",
      "input import/pool2/MaxPool:0 has 3136 elements dims = [1, 64, 7, 7]\n",
      "input import/conv3/Variable:0 has 3211264 elements dims = [1024, 64, 7, 7]\n",
      "\n",
      "-- Conv \"import/conv4last/Conv2D\" --\n",
      "input import/conv3/Relu:0 has 1024 elements dims = [1, 1024, 1, 1]\n",
      "input import/conv4last/Variable:0 has 10240 elements dims = [10, 1024, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "## parse_model.py\n",
    "\n",
    "import onnx\n",
    "\n",
    "onnx_model = onnx.load('./lenet.onnx')\n",
    "\n",
    "## need to run shape inference in order to get a full value_info list\n",
    "onnx_model = onnx.shape_inference.infer_shapes(onnx_model)\n",
    "\n",
    "## List all tensor names in the raph\n",
    "input_nlist = [k.name for k in onnx_model.graph.input]\n",
    "initializer_nlist = [k.name for k in onnx_model.graph.initializer]\n",
    "value_info_nlist = [k.name for k in onnx_model.graph.value_info]\n",
    "\n",
    "print('\\ninput list: {}'.format(input_nlist))\n",
    "print('\\ninitializer list: {}'.format(initializer_nlist))\n",
    "print('\\nvalue_info list: {}'.format(value_info_nlist))\n",
    "\n",
    "## a simple function to calculate the tensor size and extract dimension information\n",
    "def get_size(shape):\n",
    "    dims = []\n",
    "    ndim = len(shape.dim)\n",
    "    size = 1;\n",
    "    for i in range(ndim):\n",
    "        size = size * shape.dim[i].dim_value\n",
    "        dims.append(shape.dim[i].dim_value)\n",
    "    return dims, size\n",
    "\n",
    "## find all `Conv` operators and print its input information\n",
    "for i in onnx_model.graph.node:\n",
    "    if (i.op_type == 'Conv'):\n",
    "        print('\\n-- Conv \"{}\" --'.format(i.name))\n",
    "        for j in i.input:\n",
    "            if j in input_nlist:\n",
    "                idx = input_nlist.index(j)\n",
    "                (dims, size) = get_size(onnx_model.graph.input[idx].type.tensor_type.shape)\n",
    "                print('input {} has {} elements dims = {}'.format(j, size, dims  ))\n",
    "            elif j in initializer_nlist:\n",
    "                idx = initializer_nlist.index(j)\n",
    "                (dims, size) = get_size(onnx_model.graph.initializer[idx].type.tensor_type.shape)\n",
    "                print('input {} has {} elements dims = {}'.format(j, size, dims))\n",
    "            elif j in value_info_nlist:\n",
    "                idx = value_info_nlist.index(j)\n",
    "                (dims, size) = get_size(onnx_model.graph.value_info[idx].type.tensor_type.shape)\n",
    "                print('input {} has {} elements dims = {}'.format(j, size, dims))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab 2-3-2 Extracting Hidden State Tensors Using Hooks in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tensorflow/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/tensorflow/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /home/Hank/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 233M/233M [00:17<00:00, 13.6MB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "import torch\n",
    "activation = {}\n",
    "# Define a hook function\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "# Load a pre-trained AlexNet model\n",
    "model = models.alexnet(pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation from layer classifier.1: torch.Size([1, 4096])\n",
      "Activation from layer classifier.4: torch.Size([1, 4096])\n",
      "Activation from layer classifier.6: torch.Size([1, 1000])\n"
     ]
    }
   ],
   "source": [
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "\n",
    "# Dictionary to store activations from each layer\n",
    "activation = {}\n",
    "\n",
    "# Register hook to each linear layer\n",
    "for layer_name, layer in model.named_modules():\n",
    "    if isinstance(layer, torch.nn.Linear):\n",
    "        # Register forward hook\n",
    "        layer.register_forward_hook(get_activation(layer_name))\n",
    "\n",
    "# Run model inference\n",
    "data = torch.randn(1, 3, 224, 224)\n",
    "output = model(data)\n",
    "\n",
    "# Access the saved activations\n",
    "for layer in activation:\n",
    "    print(f\"Activation from layer {layer}: {activation[layer].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab 2-3-3 Model Computation Requirement Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleLinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleLinearModel,self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=10, out_features=20, bias=False)\n",
    "        self.fc2 = nn.Linear(in_features=20, out_features=15, bias=False)\n",
    "        self.fc3 = nn.Linear(in_features=15, out_features=1, bias=False)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "linear_model = SimpleLinearModel()\n",
    "sample_data = torch.randn(1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleConv, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc =  nn.Linear(in_features=32*28*28, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "x = torch.rand(1, 1, 28, 28)\n",
    "conv_model = SimpleConv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tutorial: Calculating Operations for AlexNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "model = models.alexnet(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_output_shape(input_shape, layer):\n",
    "    # Calculate the output shape for Conv2d, MaxPool2d, and Linear layers\n",
    "    if isinstance(layer, (nn.Conv2d, nn.MaxPool2d)):\n",
    "        kernel_size = (\n",
    "            layer.kernel_size\n",
    "            if isinstance(layer.kernel_size, tuple)\n",
    "            else (layer.kernel_size, layer.kernel_size)\n",
    "        )\n",
    "        stride = (\n",
    "            layer.stride\n",
    "            if isinstance(layer.stride, tuple)\n",
    "            else (layer.stride, layer.stride)\n",
    "        )\n",
    "        padding = (\n",
    "            layer.padding\n",
    "            if isinstance(layer.padding, tuple)\n",
    "            else (layer.padding, layer.padding)\n",
    "        )\n",
    "        dilation = (\n",
    "            layer.dilation\n",
    "            if isinstance(layer.dilation, tuple)\n",
    "            else (layer.dilation, layer.dilation)\n",
    "        )\n",
    "\n",
    "        output_height = (\n",
    "            input_shape[1] + 2 * padding[0] - dilation[0] * (kernel_size[0] - 1) - 1\n",
    "        ) // stride[0] + 1\n",
    "        output_width = (\n",
    "            input_shape[2] + 2 * padding[1] - dilation[1] * (kernel_size[1] - 1) - 1\n",
    "        ) // stride[1] + 1\n",
    "        return (\n",
    "            layer.out_channels if hasattr(layer, \"out_channels\") else input_shape[0],\n",
    "            output_height,\n",
    "            output_width,\n",
    "        )\n",
    "    elif isinstance(layer, nn.Linear):\n",
    "        # For Linear layers, the output shape is simply the layer's output features\n",
    "        return (layer.out_features,)\n",
    "    else:\n",
    "        return input_shape\n",
    "\n",
    "\n",
    "def calculate_macs(layer, input_shape, output_shape):\n",
    "    # Calculate MACs for Conv2d and Linear layers\n",
    "    if isinstance(layer, nn.Conv2d):\n",
    "        kernel_ops = (\n",
    "            layer.kernel_size[0]\n",
    "            * layer.kernel_size[1]\n",
    "            * (layer.in_channels / layer.groups)\n",
    "        )\n",
    "        output_elements = output_shape[1] * output_shape[2]\n",
    "        macs = int(kernel_ops * output_elements * layer.out_channels)\n",
    "        return macs\n",
    "    elif isinstance(layer, nn.Linear):\n",
    "        # For Linear layers, MACs are the product of input features and output features\n",
    "        macs = int(layer.in_features * layer.out_features)\n",
    "        return macs\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: features.0, Type: Conv2d, Input Shape: (3, 224, 224), Output Shape: (64, 55, 55), MACs: 70276800\n",
      "Layer: features.2, Type: MaxPool2d, Input Shape: (64, 55, 55), Output Shape: (64, 27, 27), MACs: N/A\n",
      "Layer: features.3, Type: Conv2d, Input Shape: (64, 27, 27), Output Shape: (192, 27, 27), MACs: 223948800\n",
      "Layer: features.5, Type: MaxPool2d, Input Shape: (192, 27, 27), Output Shape: (192, 13, 13), MACs: N/A\n",
      "Layer: features.6, Type: Conv2d, Input Shape: (192, 13, 13), Output Shape: (384, 13, 13), MACs: 112140288\n",
      "Layer: features.8, Type: Conv2d, Input Shape: (384, 13, 13), Output Shape: (256, 13, 13), MACs: 149520384\n",
      "Layer: features.10, Type: Conv2d, Input Shape: (256, 13, 13), Output Shape: (256, 13, 13), MACs: 99680256\n",
      "Layer: features.12, Type: MaxPool2d, Input Shape: (256, 13, 13), Output Shape: (256, 6, 6), MACs: N/A\n",
      "Layer: classifier.1, Type: Linear, Input Shape: (256, 6, 6), Output Shape: (4096,), MACs: 37748736\n",
      "Layer: classifier.4, Type: Linear, Input Shape: (4096,), Output Shape: (4096,), MACs: 16777216\n",
      "Layer: classifier.6, Type: Linear, Input Shape: (4096,), Output Shape: (1000,), MACs: 4096000\n",
      "Total MACs: 714188480\n"
     ]
    }
   ],
   "source": [
    "# Initial input shape\n",
    "input_shape = (3, 224, 224)\n",
    "total_macs = 0\n",
    "\n",
    "# Iterate through the layers of the model\n",
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, (nn.Conv2d, nn.MaxPool2d, nn.ReLU, nn.Linear)):\n",
    "        output_shape = calculate_output_shape(input_shape, layer)\n",
    "        macs = calculate_macs(layer, input_shape, output_shape)\n",
    "        total_macs += macs\n",
    "        if isinstance(layer, (nn.Conv2d, nn.Linear)):\n",
    "            print(\n",
    "                f\"Layer: {name}, Type: {type(layer).__name__}, Input Shape: {input_shape}, Output Shape: {output_shape}, MACs: {macs}\"\n",
    "            )\n",
    "        elif isinstance(layer, nn.MaxPool2d):\n",
    "            # Also print shape transformation for MaxPool2d layers (no MACs calculated)\n",
    "            print(\n",
    "                f\"Layer: {name}, Type: {type(layer).__name__}, Input Shape: {input_shape}, Output Shape: {output_shape}, MACs: N/A\"\n",
    "            )\n",
    "        input_shape = output_shape  # Update the input shape for the next layer\n",
    "\n",
    "print(f\"Total MACs: {total_macs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab 2-3-5 Profiling with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from torch.profiler import profile, record_function, ProfilerActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.alexnet(pretrained=True)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "inputs = torch.randn(5, 3, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-02-25 16:11:06 248:248 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2024-02-25 16:11:06 248:248 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2024-02-25 16:11:06 248:248 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                  model_inference        11.83%       5.656ms       100.00%      47.811ms      47.811ms             1  \n",
      "                     aten::linear         0.05%      24.000us        42.79%      20.457ms       6.819ms             3  \n",
      "                      aten::addmm        42.56%      20.348ms        42.65%      20.392ms       6.797ms             3  \n",
      "                     aten::conv2d         0.76%     362.000us        38.95%      18.624ms       3.725ms             5  \n",
      "                aten::convolution         0.29%     137.000us        38.20%      18.262ms       3.652ms             5  \n",
      "               aten::_convolution         0.13%      62.000us        37.91%      18.125ms       3.625ms             5  \n",
      "         aten::mkldnn_convolution        37.60%      17.978ms        37.78%      18.063ms       3.613ms             5  \n",
      "                 aten::max_pool2d         0.03%      14.000us         4.73%       2.260ms     753.333us             3  \n",
      "    aten::max_pool2d_with_indices         4.70%       2.246ms         4.70%       2.246ms     748.667us             3  \n",
      "                      aten::relu_         0.90%     430.000us         1.37%     657.000us      93.857us             7  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 47.811ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with profile(activities=[ProfilerActivity.CPU], profile_memory=True, record_shapes=True) as prof:\n",
    "    model(inputs)\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab 2-3-6 Analyzing Profiling Results Using TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim\n",
    "import torch.profiler\n",
    "import torch.utils.data\n",
    "import torchvision.datasets\n",
    "import torchvision.models\n",
    "import torchvision.transforms as T\n",
    "\n",
    "\n",
    "transform = T.Compose(\n",
    "    [T.Resize(224),\n",
    "     T.ToTensor(),\n",
    "     T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "model = torchvision.models.resnet18(weights='IMAGENET1K_V1')\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data):\n",
    "    inputs, labels = data[0].to(device=device), data[1].to(device=device)\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.profiler.profile(\n",
    "        schedule=torch.profiler.schedule(wait=1, warmup=1, active=3, repeat=1),\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler('./log/resnet18'),\n",
    "        record_shapes=True,\n",
    "        profile_memory=True,\n",
    "        with_stack=True\n",
    ") as prof:\n",
    "    for step, batch_data in enumerate(train_loader):\n",
    "        prof.step()  # Need to call this at each step to notify profiler of steps' boundary.\n",
    "        if step >= 1 + 1 + 3:\n",
    "            break\n",
    "        train(batch_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
